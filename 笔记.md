##第四章 线性回归
    读取数据文本csv文件的函数包为    github.com/go-gota/gota/dataframe    
    直观显示(画图)的函数包为       gonum.org/v1/plot
    线性回归用到的函数包为         github.com/sajari/regression
    首先分析数据，从一些统计性上， 在dataframe包下，有Describe()看一些
    最大值、最小值、平均值、标准差等标准，可以用于后续的模型检测
    
    线性回归的假设和陷阱
    需要知道，机器学习不能覆盖所有的场景、线性回归作为其中一员更是，而且，线性回归是提前假定
    因变量是随自变量线性相关的，但实际复杂的情况，并不完全是这样的，但同时，它也是最简单的假设，
    容易理解和可视化。

    线性回归的假设：
    1、线性关系：这可能是显而易见的，但是线性回归假设因变量线性依赖（通过线性方程）自变量。 
    如果这种关系是非线性的，线性回归的性能可能表现不佳。
    2、正态性：这个假设意味着变量是正态分布的（看起来像钟形）。
    3、非多重共线性：多重共线性是一个奇特的术语，它意味着自变量并不是真正独立，它们以某种方式相互依赖。
    4、无自相关性：自相关是另一个奇特的术语，它意味着变量依赖于自身或者自身的一些历史版本（例如一些可预测的时间序列）。
    5、同方差性：这可能是一系列术语中最奇特的词语，但是它意味着相对简单、并不需要经常担心的东西。
    线性回归假设自变量的所有取值在回归线附近的方差基本相同。
    从技术上讲，使用线性回归时所有这些假设应该满足。了解数据的分布和行为是非常重要的。
    当使用线性回归分析示例中的数据时，将会研究这些假设。

    线性回归的陷阱：
    1、你在为某个特定范围的自变量训练线性回归模型时。对这个范围以外的数值预测应该非常小心，
    因为回归线可能并不适用于这种情况（例如，因变量在极值处可能开始表现为非线性）。
    2、可能因为找到两个原本没有关系的变量之间的虚假关系，从而错误地采用线性回归模型。
    应当仔细检查以确保变量功能上相关是有内在逻辑原因的。
    3、在某些拟合中，数据中的异常或极值可能偏离回归线，例如OLS。有多种方法可以拟合对异常免疫的回归线，
    或者对异常敏感的回归线，例如最小正交二乘或者岭回归。
    
    岭回归 ridge regression 实现的函数包 github.com/berkmancenter/ridge

    为了避免过度拟合，应该将数据分为训练数据、测试数据、保留数据。这种方式通用于机器学习。

    书中的例子采用了循序渐进的方式，因为从数据的各自属性上看，一开始只有TV和Sales大概符合线性。
    所以采用1对1的方式，建立回归方程。从MAE这个指标为目标分析，逐步加入的Radio作为自变量。
    加入后，改善了MAE，说明添加是正确的。
    这里需要说明的是，当为模型添加更多的复杂性时(自变量数量)。牺牲了简单性，并且可能会有过度拟合的危险。
    所以只有模型性能能提升能够创造更多价值的时候，才会增加模型复杂性。

    